curl --location --request POST 'http://localhost:3000/publish' \
--header 'Content-Type: application/json' \
--data-raw '{
    "content": "---\ntitle: 在本地跑一个大语言模型(2) - 给模型提供外部知识库\ndescription: Make your local large language models (LLMs) smarter! This guide shows how to use LangChain and RAG to let them retrieve data from external knowledge bases, improving answer accuracy.\ncover: /Users/zero0043/0043/github/zo0043/ai_auto_wxgzh/image/1745251869.jpg\n---\n\n在[上一篇文章](https://babyno.top/posts/2024/02/running-a-large-language-model-locally/)中，我们展示了如何在本地运行大型语言模型。本篇将介绍如何让模型从外部知识库中检索定制数据，提升答题准确率，让它看起来更“智能”。\n\n## 准备模型\n\n访问 `Ollama` 的模型页面，搜索 `qwen`，我们使用支持中文语义的“[通义千问](https://ollama.com/library/qwen:7b)”模型进行实验。\n\n![](https://mmbiz.qpic.cn/mmbiz_jpg/Jsq9IicjScDVUjkPc6O22ZMvmaZUzof5bLDjMyLg2HeAXd0icTvlqtL7oiarSlOicTtiaiacIxpVOV1EeMKl96PhRPPw/640?wx_fmt=jpeg)",
    "theme_id": "lapis"
}'